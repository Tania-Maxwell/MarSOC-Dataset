---
title: "Collecting PDFs from Sysrev output"
author: "Tania L.G. Maxwell"
date: "`r format(Sys.time(), '%d/%m/%Y')`"
output: 
  html_document: 
    toc: TRUE
    toc_float: 
      toc_collapsed: FALSE
      smooth_scroll: FALSE
---
# Introduction

This is a script to collect pdfs from SysRev outputs. This will be done by merging original .ris files with the output .csv from Sysrev, using the paper title. 

```{r, include=FALSE}
# for scrollable output
options(width = 60)
local({
  hook_output <- knitr::knit_hooks$get('output')
  knitr::knit_hooks$set(output = function(x, options) {
    if (!is.null(options$max.height)) options$attr.output <- c(
      options$attr.output,
      sprintf('style="max-height: %s;"', options$max.height)
    )
    hook_output(x, options)
  })
})
```


```{r, message = F, error=FALSE}
# #to download the litsearchr package
# library(remotes)
# install_github("elizagrames/litsearchr", ref="main")
library(litsearchr)
library(dplyr)
library(metagear)
library(janitor)
library(synthesisr)
```
# Merging references to get DOIs

```{r}

#import the two files of bibliography, which were imported into Sysrev
original_refs <- 
    import_results(
    directory = "C:/Users/Tania/OneDrive - University of Cambridge/Documents/07_Cam_postdoc/SaltmarshC/reports/01_litsearchr/exported_to_sysrev", #absolute path
    verbose = TRUE
  )

## REVIEW FILE

# #import the sysrev exported file for the REVIEW
# review_refs <- 
#   import_results(
#     directory = "C:/Users/Tania/OneDrive - University of Cambridge/Documents/07_Cam_postdoc/SaltmarshC/reports/02_sysrev/sysrev_exports/", #absolute path
#     file = "sysrev_review.csv",
#     verbose = TRUE
#   )


## RAW data

raw_refs <- read.csv("./sysrev_exports/sysrev_raw.csv")
```


Now we can merge the two data frames by title, which will give us the 'doi' column from the original references. We can then use this in the `PDFs_collect` function of the `metagear` R package (next section). 

```{r, eval = F}
review_refs_merged <- left_join(review_refs, original_refs, by = c("title"))


#extract first author's last name (first word until comma in column "author.y")
review_refs_merged$author_first <- substr(review_refs_merged$author.y, 1, 
                                          regexpr(",",review_refs_merged$author.y)-1 ) 

#creating a column with first author last name, year and article ID from sysrev
#this will be used to name the PDFs
review_refs_merged <- review_refs_merged %>% 
  mutate(author_year_ID = paste(author_first, year, article_id, sep = "_"))

```


```{r}

raw_refs <- raw_refs %>% 
  clean_names()

raw_refs_merged <- left_join(raw_refs, original_refs, by = c("title"))


#extract first author's last name (first word until comma in column "authors")
raw_refs_merged$author_first <- substr(raw_refs_merged$authors, 1, 
                                          regexpr(",",raw_refs_merged$authors)-1 ) 
```


# Finding PDFs

To find the PDFs, 

```{r, eval = F}
dir.create("metagear_downloads") #create a directory

#collect PDFs, place in created directory, name them by author_year_ID
PDFs_collect(aDataFrame = review_refs_merged, DOIcolumn = "doi",
             FileNamecolumn = "author_year_ID", directory = "metagear_downloads",
			WindowsProxy = TRUE, showSummary = TRUE) 
```

This was the final PDF download summary:

	 46 = download error
	 40 = downloaded
	 30 = no DOI
	 26 = URL error

Downloads located in: metagear_downloads

# Exporting the merged csv file


For Review data
```{r, eval = F}
review_refs_merged_toexport <- review_refs_merged %>% 
  dplyr::select(author_year_ID, article_id, article_url, title, #selecting columns
                author.x, abstract.x, year, source_type, doi, url) %>% 
  rename(author = author.x, #renaming columns
         abstract = abstract.x,
         sysrev_url = article_url) %>% 
  relocate(author, year, article_id, title, abstract, doi, #reordereing columns
           sysrev_url, url, .after = author_year_ID) 

```

For RAW data: 
```{r}
raw_refs_merged_toexport <- raw_refs_merged %>% 
  dplyr::select(article_id, article_url, title, #selecting columns
                authors, abstract.x, year, source_type, doi, url) %>% 
  rename(author = authors, #renaming columns
         abstract = abstract.x,
         sysrev_url = article_url) %>% 
  relocate(article_id, author, year, title, abstract, doi, #reordereing columns
           sysrev_url, url, .after = source_type) 

```




```{r, eval = FALSE}

#exporting the references as a csv, to manually edit as reading through full text
write.csv(review_refs_merged_toexport, file = "review_refs_merged.csv", row.names = F)

#exporting references 
write_refs(review_refs_merged_toexport, format = "bib", file = TRUE)
```

For RAW data
```{r, eval = FALSE}

#exporting the references as a csv, to manually edit as reading through full text
write.csv(raw_refs_merged_toexport, file = "raw_refs_merged.csv", row.names = F)

#exporting references 
write_refs(raw_refs_merged_toexport, format = "bib", file = TRUE)
```


Note: it would be interesting to learn how to export the article ID into a field in the reference manager (i.e. the "extra" field in Zotero). I don't think the `write_refs()` function from `synthesisr` or the `write_bibliography()` function from `revtools` allows to do this 
